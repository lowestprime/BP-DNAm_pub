{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954f4982",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "# os.environ['CUDA_HOME'] = '/u/local/cuda/12.3'\n",
    "# os.environ['PATH'] = f\"/u/local/cuda/12.3/bin:{os.environ['PATH']}\"\n",
    "from IPython.display import display, HTML\n",
    "# adjust width % as desired\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5db3d2fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=540801236992, available=532257189888, percent=1.6, used=7452729344, free=154161917952, active=162178289664, inactive=215625682944, buffers=268931072, cached=378917658624, shared=1372160, slab=2958241792)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean unused memory\n",
    "import gc\n",
    "import psutil\n",
    "gc.collect()\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3696f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datetime import datetime\n",
    "# # import pydot\n",
    "# # import graphviz\n",
    "# # import pipdeptree\n",
    "\n",
    "# # !pipdeptree\n",
    "# # !pip freeze > requirements.txt\n",
    "# # Step 1: Create the requirements directory and filenames\n",
    "# # os.makedirs(\"requirements\", exist_ok=True)\n",
    "# current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# filename_basic = f\"requirements_{current_time}.txt\"\n",
    "# filename_detailed = f\"requirements-detailed_{current_time}.txt\"\n",
    "# filename_svg = f\"dependencies_{current_time}.svg\"\n",
    "# filepath_basic = os.path.join(\"requirements\", filename_basic)\n",
    "# filepath_detailed = os.path.join(\"requirements\", filename_detailed)\n",
    "# filepath_svg = os.path.join(\"requirements\", filename_svg)\n",
    "\n",
    "# # Step 2: Run the commands and save the output to files without printing to the cell\n",
    "# !pipdeptree 2>/dev/null | grep -E '^\\w+' > {filepath_basic} 2>/dev/null\n",
    "# !pipdeptree --freeze > {filepath_detailed} 2> /dev/null\n",
    "# !pipdeptree --graph-output dot 2> /dev/null | dot -Tsvg -o {filepath_svg} 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ac963a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import shutil\n",
    "import json\n",
    "import cupy as cp\n",
    "import anndata as ad\n",
    "import pyarrow.feather as fth\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import pyaging as pya\n",
    "from pygam import LinearGAM, LogisticGAM, s\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy import stats, sparse\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, prange\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mepylome import Manifest\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.gam.api import GLMGam, BSplines\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer  # Enable experimental features first\n",
    "from sklearn.impute import KNNImputer, IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from patsy import dmatrix\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed10425",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h5ad_file_path_final = '/u/scratch/c/cobeaman/adata_final.h5ad'\n",
    "adata_final = ad.read_h5ad(h5ad_file_path_final)\n",
    "\n",
    "# Create a backup of the original AnnData object\n",
    "adata_backup = adata_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04d9a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adata_final = adata_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62ac427e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 2442 × 731787\n",
      "    obs: 'Female', 'Age', 'Diagnosis', 'grimage2'\n",
      "    var: 'percent_na'\n",
      "    uns: 'grimage2_percent_na', 'grimage2_missing_features', 'grimage2_metadata'\n",
      "    layers: 'X_original'\n",
      "(2442, 731787)\n",
      "Index(['cg00381604', 'cg00002271', 'cg00004581', 'cg09261435', 'cg00005473',\n",
      "       'cg00005474', 'cg05728515', 'cg16535257', 'cg23803172', 'cg00006223',\n",
      "       ...\n",
      "       'cg27540367', 'cg27543103', 'cg27585557', 'cg27616751', 'cg27649037',\n",
      "       'cg27650212', 'cg27657439', 'cg27658254', 'female', 'age'],\n",
      "      dtype='object', length=731787)\n",
      "             Female   Age   Diagnosis   grimage2\n",
      "SampleID                                        \n",
      "431-BG00001     1.0  51.0    BipolarI  56.853895\n",
      "431-BG00002     1.0  33.0    BipolarI  44.490519\n",
      "431-BG00003     0.0  49.0    BipolarI  57.901585\n",
      "431-BG00004     0.0  41.0    BipolarI  58.853983\n",
      "431-BG00006     0.0  64.0    BipolarI  67.782062\n",
      "...             ...   ...         ...        ...\n",
      "431-BG01563     0.0  50.0   Bipolar I  66.372337\n",
      "431-BG01444     1.0  37.0     Bipolar  50.446918\n",
      "431-BG01403     1.0  44.0     Bipolar  55.120050\n",
      "431-BG01413     1.0  33.9  Bipolar II  47.445674\n",
      "431-BG01378     1.0  57.0  Bipolar II  62.840520\n",
      "\n",
      "[2442 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(adata_final)\n",
    "print(adata_final.X.shape)\n",
    "print(adata_final.var_names)\n",
    "print(adata_final.obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ccfaf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_grimage2_components(adata, dir=\"pyaging_data\", batch_size=1024):\n",
    "    \"\"\"\n",
    "    Wrapper function to predict GrimAge2 and its components.\n",
    "    \"\"\"\n",
    "    # First, run the original predict_age function\n",
    "    adata = pya.pred.predict_age(adata, clock_names=\"grimage2\", dir=dir, batch_size=batch_size)\n",
    "    \n",
    "    # Load the GrimAge2 model\n",
    "    model = pya.predict._pred_utils.load_clock(\"grimage2\", \"cuda\", dir, pya.logger.Logger())\n",
    "    \n",
    "    # Get the input data\n",
    "    X = adata.obsm[f\"X_grimage2\"]\n",
    "    \n",
    "    # Predict components\n",
    "    components = predict_components(model, X, batch_size)\n",
    "    \n",
    "    # Add components to adata.obs\n",
    "    for component, values in components.items():\n",
    "        adata.obs[f\"grimage2_{component}\"] = values\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def predict_components(model, X, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Helper function to predict GrimAge2 components.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    dataset = torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32))\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    components = {\n",
    "        'PACKYRS': [], 'ADM': [], 'B2M': [], 'CystatinC': [], 'GDF15': [],\n",
    "        'Leptin': [], 'PAI1': [], 'TIMP1': [], 'LogCRP': [], 'A1C': []\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch[0].to(device)\n",
    "            \n",
    "            # Predict individual components\n",
    "            for component in components.keys():\n",
    "                component_model = getattr(model, component)\n",
    "                component_features = getattr(model, f'features_{component}')\n",
    "                component_pred = component_model(batch[:, component_features])\n",
    "                components[component].append(component_pred.gpu().numpy())\n",
    "    \n",
    "    # Concatenate results\n",
    "    for component in components.keys():\n",
    "        components[component] = np.concatenate(components[component])\n",
    "    \n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6363a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----> 🏗️ Starting predict_age function\n",
      "|-----> ⚙️ Set PyTorch device started\n",
      "|-----------> Using device: cuda\n",
      "|-----> ✅ Set PyTorch device finished [0.0011s]\n",
      "|-----> 🕒 Processing clock: grimage2\n",
      "|-----------> ⚙️ Load clock started\n",
      "|-----------------> Data found in pyaging_data/grimage2.pt\n",
      "|-----------> ✅ Load clock finished [0.0055s]\n",
      "|-----------? ⚠️ Clock 'grimage2' is for research purposes only. Please check the clock's documentation or notes for more information.\n",
      "|-----------> ⚙️ Check features in adata started\n",
      "|-----------------? 380 out of 1032 features (36.82%) are missing: ['cg00036119', 'cg00456299', 'cg00480331'], etc.\n",
      "|-----------------> Using reference feature values for grimage2\n",
      "|-----------> ⚠️ Check features in adata finished [0.2154s]\n",
      "|-----------> ⚙️ Predict ages with model started\n",
      "|-----------------> There is no preprocessing necessary\n",
      "|-----------------> The postprocessing method is cox_to_years\n",
      "|-----------------> in progress: 100.0000%\n",
      "|-----------> ✅ Predict ages with model finished [0.0060s]\n",
      "|-----------> ⚙️ Add predicted ages and clock metadata to adata started\n",
      "|-----------> ✅ Add predicted ages and clock metadata to adata finished [0.0007s]\n",
      "|-----> 🎉 Done! [0.3619s]\n",
      "|-----> ⚙️ Load clock started\n",
      "|-----------------> Data found in pyaging_data/grimage2.pt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, maia, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m adata \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_grimage2_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata_final\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m, in \u001b[0;36mpredict_grimage2_components\u001b[0;34m(adata, dir, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m adata \u001b[38;5;241m=\u001b[39m pya\u001b[38;5;241m.\u001b[39mpred\u001b[38;5;241m.\u001b[39mpredict_age(adata, clock_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrimage2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdir\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the GrimAge2 model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpya\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pred_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_clock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrimage2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpya\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Get the input data\u001b[39;00m\n\u001b[1;32m     12\u001b[0m X \u001b[38;5;241m=\u001b[39m adata\u001b[38;5;241m.\u001b[39mobsm[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_grimage2\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyaging/utils/_utils.py:66\u001b[0m, in \u001b[0;36mprogress.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m logger \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Assumes logger is the last positional argument\u001b[39;00m\n\u001b[1;32m     65\u001b[0m logger\u001b[38;5;241m.\u001b[39mstart_progress(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m started\u001b[39m\u001b[38;5;124m\"\u001b[39m, indent_level\u001b[38;5;241m=\u001b[39mindent_level)\n\u001b[0;32m---> 66\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m logger\u001b[38;5;241m.\u001b[39mfinish_progress(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished\u001b[39m\u001b[38;5;124m\"\u001b[39m, indent_level\u001b[38;5;241m=\u001b[39mindent_level)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyaging/predict/_pred_utils.py:98\u001b[0m, in \u001b[0;36mload_clock\u001b[0;34m(clock_name, device, dir, logger, indent_level)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Prepare clock for inference\u001b[39;00m\n\u001b[1;32m     97\u001b[0m clock\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m clock\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clock\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1138\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move and/or cast the parameters and buffers.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m    This can be called as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \n\u001b[1;32m   1137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1138\u001b[0m     device, dtype, non_blocking, convert_to_format \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (dtype\u001b[38;5;241m.\u001b[39mis_floating_point \u001b[38;5;129;01mor\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mis_complex):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, ipu, xpu, mkldnn, opengl, opencl, ideep, hip, ve, fpga, maia, xla, lazy, vulkan, mps, meta, hpu, mtia, privateuseone device type at start of device string: gpu"
     ]
    }
   ],
   "source": [
    "adata = predict_grimage2_components(adata_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc203ad9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize logger and load clock metadata\n",
    "logger = pya.logger.LoggerManager.gen_logger(\"example\")\n",
    "metadata = pya.utils._utils.load_clock_metadata(\"pyaging_data\", logger)\n",
    "all_clocks = list(metadata.keys())\n",
    "print(\"All available clocks:\", all_clocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all clocks to process\n",
    "clocks_to_process = all_clocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab805e85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict age using GrimAge2\n",
    "# Iterate over each clock and attempt to predict age\n",
    "for clock in all_clocks:\n",
    "    try:\n",
    "        print(f\"Processing clock: {clock}\")\n",
    "        pya.pred.predict_age(adata_final, clock_names=[clock], dir=\"pyaging_data\", batch_size=1024, clean=True, verbose=True)\n",
    "        print(f\"Successfully processed clock: {clock}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process clock: {clock} due to error: {e}\")\n",
    "#pya.pred.predict_age(adata_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad1bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger\n",
    "logger = pya.logger.LoggerManager.gen_logger(\"aging_clock_logger\")\n",
    "\n",
    "# Directory for storing clock models and metadata\n",
    "dir = \"/u/project/ophoff/cobeaman/BP-DNAm/Jupyter/pyaging_data\"  # Adjust this path as needed\n",
    "\n",
    "# Ensure GPU is available\n",
    "device = \"cuda\"\n",
    "\n",
    "# Function to load the clock and attempt prediction\n",
    "def load_and_predict_clock(clock_name, adata_final, device=device, dir=dir):\n",
    "    try:\n",
    "        print(f\"Processing clock: {clock_name}\")\n",
    "\n",
    "        # Load the clock model on GPU\n",
    "        model = pya.predict._pred_utils.load_clock(clock_name, device, dir, logger)\n",
    "\n",
    "        # Perform the age prediction\n",
    "        adata_new = pya.pred.predict_age(\n",
    "            adata=adata_final, \n",
    "            clock_names=[clock_name], \n",
    "            dir=dir, \n",
    "            batch_size=1024, \n",
    "            clean=True, \n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # Simple validation check: Ensure adata_new is not None\n",
    "        if adata_new is not None:\n",
    "            print(f\"Successfully processed clock: {clock_name}\")\n",
    "            return adata_new  # Return the updated AnnData object\n",
    "        else:\n",
    "            print(f\"Failed to process clock: {clock_name}. The result was None or invalid.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process clock: {clock_name} due to error: {e}\")\n",
    "    \n",
    "    return adata_final  # Return the original AnnData object if the process failed or was invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56906e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate through each clock and process, ensuring adata_final is updated only if the process is successful\n",
    "for clock in clocks_to_process:\n",
    "    adata_final = load_and_predict_clock(clock, adata_final, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c1be4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# After processing all clocks, you can access the results in adata_final.obs\n",
    "print(\"\\nFinal AnnData object:\")\n",
    "print(adata_final)\n",
    "print(\"\\nAvailable observations (including all clock components):\")\n",
    "print(adata_final.obs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f9f17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save the updated AnnData object back to the H5AD file\n",
    "adata_final.write(h5ad_file_path_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827c32e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = pya.models.GrimAge2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cfcc93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.metadata.update({\n",
    "    \"clock_name\": 'grimage2',\n",
    "    \"data_type\": 'methylation',\n",
    "    \"species\": 'Homo sapiens',\n",
    "    \"year\": 2022,\n",
    "    \"approved_by_author\": '⌛',\n",
    "    \"citation\": \"Lu, Ake T., et al. \\\"DNA methylation GrimAge version 2.\\\" Aging (Albany NY) 14.23 (2022): 9484.\",\n",
    "    \"doi\": \"https://doi.org/10.18632/aging.204434\",\n",
    "    \"research_only\": True,\n",
    "    \"notes\": None\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80c7f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://pyaging.s3.amazonaws.com/supporting_files/grimage2_subcomponents.csv\",\n",
    "    \"https://pyaging.s3.amazonaws.com/supporting_files/grimage2.csv\",\n",
    "    \"https://pyaging.s3.amazonaws.com/supporting_files/datMiniAnnotation3_Gold.csv\",\n",
    "]\n",
    "dir = \".\"\n",
    "logger = pya.logger.Logger()\n",
    "\n",
    "for url in urls:\n",
    "    pya.utils.download(url, dir, logger, indent_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee7923e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load feature sets from CSV files\n",
    "df = pd.read_csv('grimage2_subcomponents.csv', index_col=0)\n",
    "df_grimage = pd.read_csv('grimage2.csv', index_col=0)\n",
    "\n",
    "# Identify features\n",
    "all_features = np.unique(df['var'])[2:].tolist() + ['Female', 'Age']\n",
    "model.features = all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6076c205",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function to load weights for subcomponents\n",
    "def load_model_weights(y_pred, model_attr):\n",
    "    indices = torch.tensor([all_features.index(item) for item in df.loc[df['Y.pred'] == y_pred, 'var'] if item in all_features]).long()\n",
    "    model_layer = pya.models.LinearModel(input_dim=len(indices))\n",
    "    model_layer.linear.weight.data = torch.tensor(df.loc[df['Y.pred'] == y_pred, 'beta'][1:].values).unsqueeze(0).float()\n",
    "    model_layer.linear.bias.data = torch.tensor(df.loc[df['Y.pred'] == y_pred, 'beta'].iloc[0]).float()\n",
    "    setattr(model, model_attr, model_layer)\n",
    "    setattr(model, f'features_{model_attr}', indices)\n",
    "\n",
    "# Apply the function to each subcomponent\n",
    "components = {\n",
    "    'DNAmPACKYRS': 'PACKYRS', \n",
    "    'DNAmadm': 'ADM', \n",
    "    'DNAmB2M': 'B2M',\n",
    "    'DNAmCystatin_C': 'CystatinC', \n",
    "    'DNAmGDF_15': 'GDF15',\n",
    "    'DNAmleptin': 'Leptin',\n",
    "    'DNAmpai_1': 'PAI1',\n",
    "    'DNAmTIMP_1': 'TIMP1',\n",
    "    'DNAmlog.CRP': 'LogCRP',\n",
    "    'DNAmlog.A1C': 'A1C'\n",
    "}\n",
    "\n",
    "for y_pred, model_attr in components.items():\n",
    "    load_model_weights(y_pred, model_attr)\n",
    "\n",
    "# Load base model weights\n",
    "base_model = pya.models.LinearModel(input_dim=len(df_grimage))\n",
    "base_model.linear.weight.data = torch.tensor(df_grimage['beta'].tolist()).unsqueeze(0).float()\n",
    "base_model.linear.bias.data = torch.tensor([0]).float()\n",
    "model.base_model = base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b599491",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reference_df = pd.read_csv('datMiniAnnotation3_Gold.csv', index_col=0)\n",
    "model.reference_values = reference_df.loc[model.features[:-2]]['gold'].tolist() + [1, 65]  # Example: 65-year-old female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e5750",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "weights_dir = \"../weights\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model, os.path.join(weights_dir, f\"{model.metadata['clock_name']}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4fe133",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the Feather file\n",
    "methylation_data_final_pd_prepared = fth.read_feather('/u/scratch/c/cobeaman/methylation_data_final_pd_prepared.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a46ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(methylation_data_subset_pd.columns)\n",
    "missing_features = [feature for feature in model.features if feature not in methylation_data_final_pd_prepared.columns]\n",
    "# print(\"Missing features:\", missing_features)\n",
    "missing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d57f36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ensure the feature indices are within the bounds of available data\n",
    "for y_pred, model_attr in components.items():\n",
    "    valid_indices = [all_features.index(item) for item in df.loc[df['Y.pred'] == y_pred, 'var'] if item in available_features]\n",
    "    indices = torch.tensor(valid_indices).long()\n",
    "    model_layer = pya.models.LinearModel(input_dim=len(indices))\n",
    "    model_layer.linear.weight.data = torch.tensor(df.loc[df['Y.pred'] == y_pred, 'beta'][1:].values).unsqueeze(0).float()\n",
    "    model_layer.linear.bias.data = torch.tensor(df.loc[df['Y.pred'] == y_pred, 'beta'].iloc[0]).float()\n",
    "    setattr(model, model_attr, model_layer)\n",
    "    setattr(model, f'features_{model_attr}', indices)\n",
    "\n",
    "# After adjusting indices, run the model\n",
    "input_tensor_final = torch.tensor(input_data_final, dtype=torch.float32)\n",
    "\n",
    "# Move the model to the appropriate device and data type\n",
    "model.to(torch.float32)\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "pred = model(input_tensor_final)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f89ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyaging.predict._pred_utils import predict_ages_with_model\n",
    "\n",
    "# Assuming adata_final is your AnnData object and model is already trained\n",
    "adata_final = ad.read_h5ad('/u/scratch/c/cobeaman/adata_final.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2600cecd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define your logger and device\n",
    "logger = pya.logger.Logger()\n",
    "device = \"cuda\"\n",
    "batch_size = 1024  # Set an appropriate batch size for your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32acc11b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Predict ages or biological markers\n",
    "predictions = predict_ages_with_model(adata_final, model, device, batch_size, logger)\n",
    "\n",
    "# Convert predictions to numpy and append to adata.obs\n",
    "adata_final.obs[f\"{model.metadata['clock_name']}_predictions\"] = predictions.cpu().numpy()\n",
    "\n",
    "# To view the appended DataFrame\n",
    "print(adata_final.obs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5b09f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optionally, save the updated AnnData object\n",
    "adata_final.write_h5ad('/u/scratch/c/cobeaman/adata_final_with_predictions.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934afd8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract relevant features\n",
    "# Adjust the model's features list to include only those present in the data\n",
    "available_features = [feature for feature in model.features if feature in methylation_data_final_pd_prepared.columns]\n",
    "input_data_final = methylation_data_final_pd_prepared[available_features].values\n",
    "\n",
    "# Convert to tensor and run the model\n",
    "input_tensor_final = torch.tensor(input_data_final, dtype=torch.float32)\n",
    "model.eval()\n",
    "model.to(float)\n",
    "pred = model(input_tensor_final)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a98497",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def remove_folder(path):\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "        print(f\"Deleted folder: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting folder {path}: {e}\")\n",
    "\n",
    "# Get a list of all files and folders in the current directory\n",
    "all_items = os.listdir('.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1864b1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for item in os.listdir('.'):\n",
    "    if os.path.isfile(item) and not item.endswith('.ipynb'):\n",
    "        os.remove(item)\n",
    "    elif os.path.isdir(item):\n",
    "        shutil.rmtree(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f094f51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
