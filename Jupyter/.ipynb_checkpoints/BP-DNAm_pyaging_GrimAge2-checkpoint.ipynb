{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98803f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: pandas in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: pyaging in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (0.1.9)\n",
      "Requirement already satisfied: dask in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (2024.8.0)\n",
      "Requirement already satisfied: filelock in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: triton==3.0.0 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from torch) (1.8)\n",
      "Requirement already satisfied: networkx in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from torch) (2.6.2)\n",
      "Requirement already satisfied: fsspec in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from torch) (3.0.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
      "Requirement already satisfied: pytz>=2020.1 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.3.2 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from pyaging) (1.5.1)\n",
      "Requirement already satisfied: anndata<0.11.0,>=0.10.3 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from pyaging) (0.10.8)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from dask) (3.0.0)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from dask) (0.12.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from dask) (1.4.2)\n",
      "Requirement already satisfied: click>=8.1 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from dask) (6.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from dask) (8.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from dask) (21.0)\n",
      "Collecting dask-expr<1.2,>=1.1\n",
      "  Downloading dask_expr-1.1.10-py3-none-any.whl (242 kB)\n",
      "\u001b[K     |████████████████████████████████| 242 kB 28.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: natsort in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from anndata<0.11.0,>=0.10.3->pyaging) (8.4.0)\n",
      "Requirement already satisfied: scipy>1.8 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from anndata<0.11.0,>=0.10.3->pyaging) (1.13.1)\n",
      "Requirement already satisfied: h5py>=3.1 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from anndata<0.11.0,>=0.10.3->pyaging) (3.3.0)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from anndata<0.11.0,>=0.10.3->pyaging) (1.8)\n",
      "Requirement already satisfied: exceptiongroup in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from anndata<0.11.0,>=0.10.3->pyaging) (1.2.2)\n",
      "Collecting pyarrow>=7.0.0\n",
      "  Downloading pyarrow-17.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 39.9 MB 18 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from importlib-metadata>=4.13.0->dask) (3.19.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from packaging>=20.0->dask) (2.4.7)\n",
      "Requirement already satisfied: locket in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from partd>=1.4.0->dask) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.3.2->pyaging) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /u/home/c/cobeaman/.local/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=1.3.2->pyaging) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /u/local/apps/python/3.9.6/gcc-4.8.5/lib/python3.9/site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: pyarrow, dask-expr\n",
      "Successfully installed dask-expr-1.1.10 pyarrow-17.0.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/u/local/apps/python/3.9.6/gcc-4.8.5/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch pandas numpy pyaging dask dask[dataframe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0cff830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect\n",
    "import shutil\n",
    "import json\n",
    "import torch\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import pyaging as pya\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4a54ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_246832/1498632723.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load your specific methylation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmethylation_data_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/u/project/ophoff/cobeaman/Tools/DNAmGrimAgeGitHub/input/mymetharray_final_2458_r_731788_c_08092024_081841.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmethylation_data_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/u/project/ophoff/cobeaman/Tools/DNAmGrimAgeGitHub/input/mymetharray_subset_2458_r_653_c_08092024_082626.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load your specific methylation data\n",
    "methylation_data_subset = pd.read_csv('/u/project/ophoff/cobeaman/Tools/DNAmGrimAgeGitHub/input/mymetharray_subset_2458_r_653_c_08092024_082626.csv', index_col=0)\n",
    "# Load the large CSV file using Dask\n",
    "methylation_data_final = dd.read_csv('/u/project/ophoff/cobeaman/Tools/DNAmGrimAgeGitHub/input/mymetharray_final_2458_r_731788_c_08092024_081841.csv', assume_missing=True, blocksize='100MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Female' column is binary (0 or 1)\n",
    "methylation_data_final['Female'] = (methylation_data_final['Female'] == 1).astype(int)\n",
    "methylation_data_subset['Female'] = (methylation_data_subset['Female'] == 1).astype(int)\n",
    "\n",
    "# Handle any missing data (if necessary)\n",
    "# methylation_data_final.dropna(inplace=True)\n",
    "# methylation_data_subset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb21dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrames to AnnData objects\n",
    "adata_final = pya.pp.df_to_adata(methylation_data_final, metadata_cols=['Female', 'age'], imputer_strategy='knn')\n",
    "adata_subset = pya.pp.df_to_adata(methylation_data_subset, metadata_cols=['Female', 'age'], imputer_strategy='knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict age using GrimAge2 for both datasets\n",
    "pya.pred.predict_age(adata_final, ['GrimAge2'])\n",
    "pya.pred.predict_age(adata_subset, ['GrimAge2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31805016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first few rows of predictions\n",
    "print(adata_final.obs[['GrimAge2']].head())\n",
    "print(adata_subset.obs[['GrimAge2']].head())\n",
    "\n",
    "# Save predictions to CSV files\n",
    "adata_final.obs[['GrimAge2']].to_csv('GrimAge2_predictions_final.csv')\n",
    "adata_subset.obs[['GrimAge2']].to_csv('GrimAge2_predictions_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cfa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pya.models.GrimAge2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4af98fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metadata.update({\n",
    "    \"clock_name\": 'grimage2',\n",
    "    \"data_type\": 'methylation',\n",
    "    \"species\": 'Homo sapiens',\n",
    "    \"year\": 2022,\n",
    "    \"approved_by_author\": '⌛',\n",
    "    \"citation\": \"Lu, Ake T., et al. \\\"DNA methylation GrimAge version 2.\\\" Aging (Albany NY) 14.23 (2022): 9484.\",\n",
    "    \"doi\": \"https://doi.org/10.18632/aging.204434\",\n",
    "    \"research_only\": True,\n",
    "    \"notes\": None\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25129a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-----------> Downloading data to ./grimage2_subcomponents.csv\n",
      "|-----------> in progress: 100.0000%\n",
      "|-----------> Downloading data to ./grimage2.csv\n",
      "|-----------> in progress: 100.0000%%\n",
      "|-----------> Downloading data to ./datMiniAnnotation3_Gold.csv\n",
      "|-----------> in progress: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://pyaging.s3.amazonaws.com/supporting_files/grimage2_subcomponents.csv\",\n",
    "    \"https://pyaging.s3.amazonaws.com/supporting_files/grimage2.csv\",\n",
    "    \"https://pyaging.s3.amazonaws.com/supporting_files/datMiniAnnotation3_Gold.csv\",\n",
    "]\n",
    "dir = \".\"\n",
    "logger = pya.logger.Logger()\n",
    "\n",
    "for url in urls:\n",
    "    pya.utils.download(url, dir, logger, indent_level=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b31152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature sets from CSV files\n",
    "df = pd.read_csv('grimage2_subcomponents.csv', index_col=0)\n",
    "df_grimage = pd.read_csv('grimage2.csv', index_col=0)\n",
    "\n",
    "# Identify features\n",
    "all_features = np.unique(df['var'])[2:].tolist() + ['Female', 'Age']\n",
    "model.features = all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6076c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load weights for subcomponents\n",
    "def load_model_weights(y_pred, model_attr):\n",
    "    indices = torch.tensor([all_features.index(item) for item in df.loc[df['Y.pred'] == y_pred, 'var'] if item in all_features]).long()\n",
    "    model_layer = pya.models.LinearModel(input_dim=len(indices))\n",
    "    model_layer.linear.weight.data = torch.tensor(df.loc[df['Y.pred'] == y_pred, 'beta'][1:].values).unsqueeze(0).float()\n",
    "    model_layer.linear.bias.data = torch.tensor(df.loc[df['Y.pred'] == y_pred, 'beta'].iloc[0]).float()\n",
    "    setattr(model, model_attr, model_layer)\n",
    "    setattr(model, f'features_{model_attr}', indices)\n",
    "\n",
    "# Apply the function to each subcomponent\n",
    "components = {\n",
    "    'DNAmPACKYRS': 'PACKYRS', \n",
    "    'DNAmadm': 'ADM', \n",
    "    'DNAmB2M': 'B2M',\n",
    "    'DNAmCystatin_C': 'CystatinC', \n",
    "    'DNAmGDF_15': 'GDF15',\n",
    "    'DNAmleptin': 'Leptin',\n",
    "    'DNAmpai_1': 'PAI1',\n",
    "    'DNAmTIMP_1': 'TIMP1',\n",
    "    'DNAmlog.CRP': 'LogCRP',\n",
    "    'DNAmlog.A1C': 'A1C'\n",
    "}\n",
    "\n",
    "for y_pred, model_attr in components.items():\n",
    "    load_model_weights(y_pred, model_attr)\n",
    "\n",
    "# Load base model weights\n",
    "base_model = pya.models.LinearModel(input_dim=len(df_grimage))\n",
    "base_model.linear.weight.data = torch.tensor(df_grimage['beta'].tolist()).unsqueeze(0).float()\n",
    "base_model.linear.bias.data = torch.tensor([0]).float()\n",
    "model.base_model = base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b599491",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df = pd.read_csv('datMiniAnnotation3_Gold.csv', index_col=0)\n",
    "model.reference_values = reference_df.loc[model.features[:-2]]['gold'].tolist() + [1, 65]  # Example: 65-year-old female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.preprocess_name = None\n",
    "model.preprocess_dependencies = None\n",
    "model.postprocess_name = 'cox_to_years'\n",
    "model.postprocess_dependencies = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af411719",
   "metadata": {},
   "outputs": [],
   "source": [
    "pya.utils.print_model_details(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d329d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"../weights/{model.metadata['clock_name']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb80293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant features\n",
    "input_data_final = methylation_data_final[model.features].values\n",
    "input_data_subset = methylation_data_subset[model.features].values\n",
    "\n",
    "# Convert to tensor and run the model\n",
    "input_tensor_final = torch.tensor(input_data_final, dtype=torch.float32)\n",
    "model.eval()\n",
    "model.to(float)\n",
    "pred = model(input_tensor_final)\n",
    "print(pred)\n",
    "\n",
    "# Convert to tensor and run the model\n",
    "input_tensor_subset = torch.tensor(input_data_subset, dtype=torch.float32)\n",
    "model.eval()\n",
    "model.to(float)\n",
    "pred = model(input_tensor_final)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ca501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_folder(path):\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "        print(f\"Deleted folder: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting folder {path}: {e}\")\n",
    "\n",
    "# Get a list of all files and folders in the current directory\n",
    "all_items = os.listdir('.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7def56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in os.listdir('.'):\n",
    "    if os.path.isfile(item) and not item.endswith('.ipynb'):\n",
    "        os.remove(item)\n",
    "    elif os.path.isdir(item):\n",
    "        shutil.rmtree(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
