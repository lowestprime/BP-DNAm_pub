object_names <- ls(envir = .GlobalEnv)
if (length(object_names) > 0) {
object_sizes <- sapply(object_names, function(x) lobstr::obj_size(get(x, envir = .GlobalEnv)))
object_df <- data.frame(
Name = names(object_sizes),
Size_GB = round(as.numeric(object_sizes) / (1024^3), 2),
Type = "Object",
stringsAsFactors = FALSE
)
} else {
object_df <- data.frame(Name = character(), Size_GB = numeric(), Type = character(), stringsAsFactors = FALSE)
}
# Get memory usage of all loaded packages
package_names <- search()
package_names <- package_names[grepl("package:", package_names)]
package_names <- gsub("package:", "", package_names)
if (length(package_names) > 0) {
get_package_memory <- function(pkg) {
pkg_objects <- ls(paste("package", pkg, sep = ":"))
total_size <- sum(sapply(pkg_objects, function(x) {
tryCatch({
obj <- get(x, envir = asNamespace(pkg), inherits = FALSE)
lobstr::obj_size(obj)
}, error = function(e) {
return(0)
})
}))
return(total_size)
}
package_memory <- sapply(package_names, get_package_memory)
package_df <- data.frame(
Name = names(package_memory),
Size_GB = round(as.numeric(package_memory) / (1024^3), 2),
Type = "Package",
stringsAsFactors = FALSE
)
} else {
package_df <- data.frame(Name = character(), Size_GB = numeric(), Type = character(), stringsAsFactors = FALSE)
}
# Combine and sort the data frames
combined_df <- rbind(object_df, package_df)
sorted_combined_df <- combined_df[order(combined_df$Size_GB, decreasing = TRUE), ]
# Add total row at the top
total_size <- sum(sorted_combined_df$Size_GB)
total_df <- data.frame(Name = "Total", Size_GB = round(total_size, 2), Type = "Total", stringsAsFactors = FALSE)
final_df <- rbind(total_df, sorted_combined_df)
# Print the final data frame without scientific notation
options(scipen = 999)
print(final_df, row.names = FALSE)
rm(*_df)
ls(*_df)
ls("*_df")
ls(pattern=_df)
ls(pattern="_df")
rm(ls(pattern = "_df"))
rm(list = ls(pattern = "_df"))
# Get memory usage of all objects
object_names <- ls(envir = .GlobalEnv)
if (length(object_names) > 0) {
object_sizes <- sapply(object_names, function(x) lobstr::obj_size(get(x, envir = .GlobalEnv)))
object_df <- data.frame(
Name = names(object_sizes),
Size_MB = round(as.numeric(object_sizes) / (1024^2), 3),
Type = "Object",
stringsAsFactors = FALSE
)
} else {
object_df <- data.frame(Name = character(), Size_MB = numeric(), Type = character(), stringsAsFactors = FALSE)
}
# Get memory usage of all loaded packages
package_names <- search()
package_names <- package_names[grepl("package:", package_names)]
package_names <- gsub("package:", "", package_names)
if (length(package_names) > 0) {
get_package_memory <- function(pkg) {
pkg_objects <- ls(paste("package", pkg, sep = ":"))
total_size <- sum(sapply(pkg_objects, function(x) {
tryCatch({
obj <- get(x, envir = asNamespace(pkg), inherits = FALSE)
lobstr::obj_size(obj)
}, error = function(e) {
return(0)
})
}))
return(total_size)
}
package_memory <- sapply(package_names, get_package_memory)
package_df <- data.frame(
Name = names(package_memory),
Size_MB = round(as.numeric(package_memory) / (1024^2), 3),
Type = "Package",
stringsAsFactors = FALSE
)
} else {
package_df <- data.frame(Name = character(), Size_MB = numeric(), Type = character(), stringsAsFactors = FALSE)
}
# Combine and sort the data frames
combined_df <- rbind(object_df, package_df)
sorted_combined_df <- combined_df[order(combined_df$Size_MB, decreasing = TRUE), ]
# Add total row at the top
total_size <- sum(sorted_combined_df$Size_MB)
total_df <- data.frame(Name = "Total", Size_MB = round(total_size, 3), Type = "Total", stringsAsFactors = FALSE)
final_df <- rbind(total_df, sorted_combined_df)
# Print the final data frame without scientific notation
options(scipen = 999)
row.names(final_df) <- NULL
print(final_df)
gc()
memory.profile()
system("top -b -n1 -o %MEM | head -n 20")
gc()
# Get memory usage of all objects
object_names <- ls(envir = .GlobalEnv)
if (length(object_names) > 0) {
object_sizes <- sapply(object_names, function(x) lobstr::obj_size(get(x, envir = .GlobalEnv)))
object_df <- data.frame(
Name = names(object_sizes),
Size_MB = round(as.numeric(object_sizes) / (1024^2), 3),
Type = "Object",
stringsAsFactors = FALSE
)
} else {
object_df <- data.frame(Name = character(), Size_MB = numeric(), Type = character(), stringsAsFactors = FALSE)
}
# Get memory usage of all loaded packages
package_names <- search()
package_names <- package_names[grepl("package:", package_names)]
package_names <- gsub("package:", "", package_names)
if (length(package_names) > 0) {
get_package_memory <- function(pkg) {
pkg_objects <- ls(paste("package", pkg, sep = ":"))
total_size <- sum(sapply(pkg_objects, function(x) {
tryCatch({
obj <- get(x, envir = asNamespace(pkg), inherits = FALSE)
lobstr::obj_size(obj)
}, error = function(e) {
return(0)
})
}))
return(total_size)
}
package_memory <- sapply(package_names, get_package_memory)
package_df <- data.frame(
Name = names(package_memory),
Size_MB = round(as.numeric(package_memory) / (1024^2), 3),
Type = "Package",
stringsAsFactors = FALSE
)
} else {
package_df <- data.frame(Name = character(), Size_MB = numeric(), Type = character(), stringsAsFactors = FALSE)
}
# Combine and sort the data frames
combined_df <- rbind(object_df, package_df)
sorted_combined_df <- combined_df[order(combined_df$Size_MB, decreasing = TRUE), ]
# Add total row at the top
total_size <- sum(sorted_combined_df$Size_MB)
total_df <- data.frame(Name = "Total", Size_MB = round(total_size, 3), Type = "Total", stringsAsFactors = FALSE)
final_df <- rbind(total_df, sorted_combined_df)
# Print the final data frame without scientific notation
options(scipen = 999)
row.names(final_df) <- NULL
print(final_df)
pacman::p_load(pryr)
mem_used()
lobstr::mem_used()
# Get memory usage of all objects
object_names <- ls(envir = .GlobalEnv)
if (length(object_names) > 0) {
object_sizes <- sapply(object_names, function(x) lobstr::obj_size(get(x, envir = .GlobalEnv)))
object_df <- data.frame(
Name = names(object_sizes),
Size_MB = round(as.numeric(object_sizes) / (1024^2), 3),
Type = "Object",
stringsAsFactors = FALSE
)
} else {
object_df <- data.frame(Name = character(), Size_MB = numeric(), Type = character(), stringsAsFactors = FALSE)
}
# Get memory usage of all loaded packages
package_names <- search()
package_names <- package_names[grepl("package:", package_names)]
package_names <- gsub("package:", "", package_names)
if (length(package_names) > 0) {
get_package_memory <- function(pkg) {
pkg_objects <- ls(paste("package", pkg, sep = ":"))
total_size <- sum(sapply(pkg_objects, function(x) {
tryCatch({
obj <- get(x, envir = asNamespace(pkg), inherits = FALSE)
lobstr::obj_size(obj)
}, error = function(e) {
return(0)
})
}))
return(total_size)
}
package_memory <- sapply(package_names, get_package_memory)
package_df <- data.frame(
Name = names(package_memory),
Size_MB = round(as.numeric(package_memory) / (1024^2), 3),
Type = "Package",
stringsAsFactors = FALSE
)
} else {
package_df <- data.frame(Name = character(), Size_MB = numeric(), Type = character(), stringsAsFactors = FALSE)
}
# Combine and sort the data frames
combined_df <- rbind(object_df, package_df)
sorted_combined_df <- combined_df[order(combined_df$Size_MB, decreasing = TRUE), ]
# Add total row at the top
total_size <- sum(sorted_combined_df$Size_MB)
total_df <- data.frame(Name = "Total", Size_MB = round(total_size, 3), Type = "Total", stringsAsFactors = FALSE)
final_df <- rbind(total_df, sorted_combined_df)
# Print the final data frame without scientific notation
options(scipen = 999)
row.names(final_df) <- NULL
print(final_df)
object_sizes <- sapply(ls(), function(x) object.size(get(x)))
print(object_sizes)
closeAllConnections()
closeAllConnections()
ls(all.names = TRUE)
object.size(all.names=T)
sessionInfo()
large_objects <- sapply(ls(all.names = TRUE), function(x) object.size(get(x)))
large_objects <- sort(large_objects, decreasing = TRUE)
print(large_objects)
setwd('~/')
setwd('/etc/rstudio/rserver.conf')
setwd('/etc/rstudio/rserver.conf')
setwd('~/etc/rstudio/rserver.conf')
gc()
gc()
library(memtools)
# Function to inspect and take snapshots of each environment
inspect_environment <- function(index) {
env <- ns_registry[[index]]
cat("Inspecting environment", index, ":", names(ns_registry)[index], "\n")
print(env)
# Take snapshot with error handling
tryCatch({
s <- mem_snapshot(list(env))
print(s)
}, error = function(e) {
cat("Error in snapshot for environment", index, ":", e$message, "\n")
})
}
# Inspect and take snapshots of each environment individually
for (i in seq_along(ns_registry)) {
inspect_environment(i)
}
ns_registry <- root_ns_registry()
# Function to inspect and take snapshots of each environment
inspect_environment <- function(index) {
env <- ns_registry[[index]]
cat("Inspecting environment", index, ":", names(ns_registry)[index], "\n")
print(env)
# Take snapshot with error handling
tryCatch({
s <- mem_snapshot(list(env))
print(s)
}, error = function(e) {
cat("Error in snapshot for environment", index, ":", e$message, "\n")
})
}
# Inspect and take snapshots of each environment individually
for (i in seq_along(ns_registry)) {
inspect_environment(i)
}
# Inspect objects within each environment individually
for (i in seq_along(ns_registry)) {
env_name <- names(ns_registry)[i]
env <- ns_registry[[i]]
inspect_environment_objects(env_name, env)
}
inspect_environment_objects <- function(env_name, env) {
cat("Inspecting environment:", env_name, "\n")
env_objects <- ls(env, all.names = TRUE)
for (obj_name in env_objects) {
cat("  Inspecting object:", obj_name, "\n")
obj <- try(get(obj_name, envir = env), silent = TRUE)
# Skip if object cannot be accessed
if (inherits(obj, "try-error")) {
cat("  Cannot access object:", obj_name, "\n")
next
}
# Take snapshot with error handling
tryCatch({
s <- mem_snapshot(list(obj))
print(s)
}, error = function(e) {
cat("  Error in snapshot for object:", obj_name, ":", e$message, "\n")
})
}
# Inspect objects within each environment individually
for (i in seq_along(ns_registry)) {
env_name <- names(ns_registry)[i]
env <- ns_registry[[i]]
inspect_environment_objects(env_name, env)
}
# Function to inspect and take snapshots of each object within an environment
inspect_environment_objects <- function(env_name, env) {
cat("Inspecting environment:", env_name, "\n")
env_objects <- ls(env, all.names = TRUE)
for (obj_name in env_objects) {
cat("  Inspecting object:", obj_name, "\n")
obj <- try(get(obj_name, envir = env), silent = TRUE)
# Skip if object cannot be accessed
if (inherits(obj, "try-error")) {
cat("  Cannot access object:", obj_name, "\n")
next
}
# Take snapshot with error handling
tryCatch({
s <- mem_snapshot(list(obj))
cat("  Successfully snapped object:", obj_name, "\n")
print(s)
}, error = function(e) {
cat("  Error in snapshot for object:", obj_name, ":", e$message, "\n")
})
}
# Inspect objects within each environment individually
for (i in seq_along(ns_registry)) {
env_name <- names(ns_registry)[i]
env <- ns_registry[[i]]
inspect_environment_objects(env_name, env)
}
setwd('/u/project/ophoff/cobeaman/BP-DNAm')
setwd('~/')
setwd('/u/project/ophoff/cobeaman/BP-DNAm')
setwd('~/')
load("/u/project/ophoff/cobeaman/BP-DNAm/.RData")
load("/u/project/lhernand/cobeaman/ABCD_Longitudinal_Subcortical_Imaging_GWAS/long_smri_roc_gcta.RData")
setwd("/u/project/lhernand/cobeaman/ABCD_Longitudinal_Subcortical_Imaging_GWAS")
# Go to project dir or skip and run in current project dir
setwd("~/project-ophoff/BP-DNAm")
# load packages
if (!require("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(dplyr, tidyr, stringr, readr, readxl, data.table, lubridate, tibble)
# Read in Bipolar 2023 Sample Sheet.csv as data frame and remove Pool_ID col
BPDNAm_SS <- read.csv("Bipolar 2023 Sample Sheet.csv") %>%
select(-Pool_ID)
# Read in 2000_sample_covariates.csv as data frame, remove Pool_ID col and rename 'Sample_id' col
BPDNAm_ext <- read.csv("From_Roel/2000_sample_covariates.csv") %>%
select(-RIN) %>%
rename(Sample_Name = Sample_id,
Age_Years = Sample.Age
) %>%
mutate(Age_Years = as.numeric(gsub("[^0-9.]", "", Age_Years)),
Gender = recode(Gender, "Female" = "F", "Male" = "M")) # Remove non-numeric characters and convert to numeric
# Read in highcov_technical_covariates.txt as data frame
BPDNAm_cov <- read.table("From_Roel/highcov_technical_covariates.txt", sep = "\t", header = TRUE, row.names = 1) %>%
t() %>%
as_tibble(rownames = "Sample_Name") %>%
select(Sample_Name, !starts_with("/u/project/")) %>%
rename(Gender = sex,
Diagnosis = diagnosis,
Age_Years = age) %>%
mutate(Age_Years = as.numeric(gsub("[^0-9.]", "", Age_Years)), # Remove non-numeric characters and convert to numeric
Sample_Name = gsub("^X(\\d{3})\\.(BG\\d{5})$", "\\1-\\2", Sample_Name)) # Change Sample_Name format
# Read in Complete BIG Data.xlsx as data frame
bp_master <- read_excel("Complete BIG Data.xlsx")
# Rename 'Sample_id' in bp_master to 'Sample_Name' for matching and remove duplicate entries
bp_master <- bp_master %>%
rename(Sample_Name = Sample_id) %>%
group_by(Sample_Name) %>%
filter(`Date of sample collection` == max(`Date of sample collection`)) %>%
slice(1) %>%
ungroup()
# Create BPDNAm_SS missing entries df for samples not present in bp_master
missing_samples <- BPDNAm_SS %>%
anti_join(bp_master, by = "Sample_Name")
# Identify columns in bp_master that are not in BPDNAm_SS
new_cols <- setdiff(colnames(bp_master), colnames(BPDNAm_SS))
# Merge BPDNAm_SS with only the new columns from bp_master
BPDNAm_SS_updated <- BPDNAm_SS %>%
left_join(bp_master %>% select(Sample_Name, all_of(new_cols)), by = "Sample_Name") %>%
mutate(
Age_Months = interval(`Date of birth`, `Date of sample collection`) %>%
time_length(unit = "months") %>%
floor(),
Age_Years = interval(`Date of birth`, `Date of sample collection`) %>%
time_length(unit = "years") %>%
floor()
) %>%
select(Sample_Name, all_of(new_cols), Age_Years, Age_Months)
# Columns to check for missing values
columns_to_check <- c("Age_Years", "Gender", "Diagnosis")
# Merging and filling more missing values from BPDNAm_cov and BPDNAm_ext
BPDNAm_SS_updated <- BPDNAm_SS_updated %>%
left_join(select(BPDNAm_cov, Sample_Name, Gender, Diagnosis, Age_Years), by = "Sample_Name", suffix = c("", ".cov")) %>%
left_join(select(BPDNAm_ext, Sample_Name, Gender, Diagnosis, Age_Years), by = "Sample_Name", suffix = c("", ".ext")) %>%
mutate(
Gender = coalesce(Gender.cov, Gender.ext, Gender),
Diagnosis = coalesce(Diagnosis.cov, Diagnosis.ext, Diagnosis),
Age_Years = coalesce(Age_Years.cov, Age_Years.ext, Age_Years),
Age_Months = if_else(
is.na(interval(`Date of birth`, `Date of sample collection`) %>%
time_length(unit = "months") %>%
floor()),
Age_Years * 12,
interval(`Date of birth`, `Date of sample collection`) %>%
time_length(unit = "months") %>%
floor()
)
) %>%
select(-ends_with(".cov"), -ends_with(".ext"))
# summarize Sample_Names with _Rep pair
BPDNAm_SS_REP <- BPDNAm_SS_updated %>%
mutate(base_name = str_remove(Sample_Name, "_REP$")) %>%
group_by(base_name) %>%
filter(n() == 2 & sum(str_detect(Sample_Name, "_REP$")) == 1) %>%
ungroup() %>%
select(-base_name) %>%
arrange(Sample_Name) %>%
left_join(BPDNAm_SS %>% select(Sample_Name, Basename, Sample_Plate, Sample_Well, Sentrix_ID, Sentrix_Position, Sample_Group),
by = "Sample_Name")
# Export BPDNAm_SS_REP with a filename including the count of "_REP" samples
# BPDNAm_SS_REP %>%
#   {
#     num_rep_samples <- sum(str_detect(.$Sample_Name, "_REP$"))
#     filename <- sprintf("BPDNAm_SS_REP_Pairs_%d.csv", num_rep_samples)
#     fwrite(., filename)
#   }
# summarize NAs in BPDNAm_SS_updated
NA_summary <- BPDNAm_SS_updated %>%
summarise(across(everything(), ~sum(is.na(.)) / n())) %>%
pivot_longer(everything(), names_to = "Column", values_to = "NA_Proportion") %>%
mutate(
NA_Count = round(NA_Proportion * nrow(bp_master))
) %>%
filter(NA_Count > 0) %>%
arrange(desc(NA_Proportion))
# Export NA_summary
# fwrite(NA_summary, "BPDNAm_NA_Summary.csv")
# Identify columns to keep (NA proportion < 0.2)
cols_to_keep <- NA_summary %>%
filter(NA_Proportion < 0.2) %>%
pull(Column) %>%
setdiff(c("Serum", "Plasma", "Type of sample", "Time of inclusion", "AZU NR"))
# Create a subset of BPDNAm_SS_updated with cols_to_keep and NA rows joining in cols from missing_data
BPDNAm_SS_NAs <- BPDNAm_SS_updated %>%
select(Sample_Name, all_of(cols_to_keep), -c("Fam_code", "Date of birth", "Date of sample collection", "Age_Months")) %>%
filter(if_any(everything(), is.na)) %>%
left_join(missing_samples, by = "Sample_Name") %>%
select(-c("Sample_Group", "Basename"))
# Export BPDNAm_SS_NAs
# BPDNAm_SS_NAs %>%
#   {
#     num_samples <- nrow(.)
#     filename <- sprintf("BPDNAm_NA_Samples_%d.csv", num_samples)
#     fwrite(., filename)
#   }
# Export comma separated list of Sample_Names in BPDNAm_SS_NAs
# BPDNAm_SS_NAs %>%
#   pull(Sample_Name) %>%
#   {
#     sample_names <- .
#     filename <- sprintf("BPDNAm_NA_Sample_Names_%d.txt", length(sample_names))
#     paste(sample_names, collapse = ",") %>%
#       write_file(filename)
#   }
# Create a subset of BPDNAm_SS_updated with cols_to_keep and no NA rows
BPDNAm_SS_noNAs <- BPDNAm_SS_updated %>%
select(Sample_Name, all_of(cols_to_keep), -c("Fam_code", "Date of birth", "Date of sample collection")) %>%
anti_join(BPDNAm_SS_NAs, by = "Sample_Name")
View(BPDNAm_cov)
View(BPDNAm_SS_updated)
View(NA_summary)
$SCRATCH
system($SCRATCH)
system(SCRATCH)
setwd($SCRATCH)
setwd(/u/scratch/c/cobeaman)
setwd("/u/scratch/c/cobeaman")
list.files()
pacman::p_load(minfi, igraph, dplyr, leiden, bigstatsr, foreach, doParallel,
data.table, BioAge, dnaMethyAge, meffil, methylclock,
qs, ggplot2, plotly, RColorBrewer, reshape2, GenomicRanges,
SummarizedExperiment, tidyverse, purrr)
n_cores <- 36  # Number of cores to use, matching HPC resources
cl <- makeCluster(n_cores)
registerDoParallel(cl)
View(cl)
Sys.getenv("TMPDIR")
temp_data_file_path <- file.path(Sys.getenv("TMPDIR"), "Density_Data.qs")
temp_data_file_path <- file.path(Sys.getenv("SCRATCH"), "Density_Data.qs")
data_file_path <- "Density_Data.qs"
temp_data_file_path <- file.path(Sys.getenv("SCRATCH"), "Density_Data.qs")
file.copy(data_file_path, temp_data_file_path)
beta_values <- qread(data_file_path, nthreads = 36)$beta_values
beta_values_fbm <- as_FBM(beta_values)
big_cor_parallel <- function(X, size = 1000, fun = cor, method = "pearson") {
n <- ncol(X)
m <- matrix(0, n, n)
# Parallel computation with foreach
foreach(i = seq(1, n, by = size), .combine = 'cbind', .packages = 'bigstatsr') %dopar% {
chunk_m <- matrix(0, size, n)  # Initialize a chunk matrix
for (j in seq(i, n, by = size)) {
end_i <- min(i + size - 1, n)
end_j <- min(j + size - 1, n)
if (i == j) {
chunk_m[1:(end_i - i + 1), j:(end_j)] <- fun(X[, i:end_i], method = method)
} else {
corr_block <- fun(X[, i:end_i], X[, j:end_j], method = method)
chunk_m[1:(end_i - i + 1), j:(end_j)] <- corr_block
m[j:end_j, i:end_i] <- t(corr_block)
}
m[i:end_i, ] <- chunk_m[1:(end_i - i + 1), ]
}
return(m)
}
similarity_matrix <- big_cor_parallel(beta_values_fbm, fun = cor, method = "pearson")
